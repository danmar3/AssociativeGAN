{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acgan\n",
    "import acgan.model.gmm_gan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import twodlearn as tdl\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "BATCH_SIZE = 16\n",
    "#acgan.data.DATA_DIR = '/data/marinodl/tensorflow_datasets'\n",
    "\n",
    "RESTORE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = acgan.data.load_celeb_a_128_cropped(BATCH_SIZE)\n",
    "#dataset = acgan.data.load_mnist32(BATCH_SIZE)\n",
    "input_shape = dataset.output_shapes.as_list()\n",
    "print('input shape: {}'.format(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twodlearn.debug\n",
    "@tdl.debug.stop_at_error\n",
    "def _test():\n",
    "    model = acgan.model.gmm_gan.GmmGan(\n",
    "        embedding_size=64,\n",
    "        embedding={'n_components': 100},\n",
    "        encoder={'units':[32, 64, 64, 64], #1024\n",
    "                 'kernels':3,\n",
    "                 'strides':2},\n",
    "        generator={'init_shape':(4, 4, 64),\n",
    "                   'units': [256, 128, 64, 32, 16],\n",
    "                   'outputs': 3,\n",
    "                   'kernels': 3,\n",
    "                   'strides': 2},\n",
    "        discriminator={'units':[16, 32, 64, 128, 256], #1024\n",
    "                       'kernels':3,\n",
    "                       'strides':2,\n",
    "                       'dropout':None}\n",
    "    )\n",
    "    return model\n",
    "model = _test()\n",
    "#model.noise_rate.init(rate=0.001)\n",
    "print('output shape: {}'.format(\n",
    "    model.generator.compute_output_shape(\n",
    "        input_shape=[None, 100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = dataset.make_one_shot_iterator()\n",
    "xreal = iter.get_next()\n",
    "\n",
    "import twodlearn.debug\n",
    "@tdl.debug.stop_at_error\n",
    "def _test():\n",
    "    gen = model.generator_trainer(\n",
    "        BATCH_SIZE,\n",
    "        optimizer={'learning_rate': 0.0005, 'beta1': 0.0}\n",
    "        # pyramid_loss={'scale': 1e-6},\n",
    "        # regularizer={'scale': 1e-6}\n",
    "        )\n",
    "        #regularizer={'scale': 1e-5})\n",
    "    dis = model.discriminator_trainer(\n",
    "        BATCH_SIZE, xreal=xreal, \n",
    "        optimizer={'learning_rate': 0.0005, 'beta1': 0.0}\n",
    "        # regularizer={'scale': 1e-6}\n",
    "        )\n",
    "        #regularizer={'scale': 1e-5})\n",
    "    enc = model.encoder_trainer(\n",
    "        BATCH_SIZE,\n",
    "        optimizer={'learning_rate': 0.0005, 'beta1': 0.0}\n",
    "        )\n",
    "    tdl.core.variables_initializer(gen.variables).run()\n",
    "    tdl.core.variables_initializer(dis.variables).run()\n",
    "    tdl.core.variables_initializer(enc.variables).run()\n",
    "    return gen, dis, enc\n",
    "gen, dis, enc = _test()\n",
    "\n",
    "if RESTORE:\n",
    "    saver = tf.train.Saver(tdl.core.get_variables(model))\n",
    "    saver.restore(session, 'tmp/GmmGan_vars_20190910:1757.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('step {} | dis {} | gen {}'.format(dis.train_step.eval(), dis.loss.eval(), gen.loss.eval()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in tqdm.tqdm(range(100)):\n",
    "#if True:\n",
    "    acgan.train.run_training(dis=dis, gen=gen, n_steps=200, n_logging=10)\n",
    "    for i in tqdm.tqdm(range(200)):\n",
    "        session.run(enc.step['encoder'])\n",
    "    for i in tqdm.tqdm(range(20)):\n",
    "        session.run(enc.step['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return ((image-image.min())/(image.max()-image.min()))\n",
    "fig, ax = plt.subplots(4,4, figsize=(20, 20))\n",
    "ax = np.reshape(ax, 4*4)\n",
    "xsim =  session.run(gen.xsim) #dis.sim_pyramid[-1].eval()\n",
    "for i in range(4*4):\n",
    "    image = (xsim[i][:,:,:]+1)*0.5\n",
    "    ax[i].imshow(np.squeeze(normalize(image)),\n",
    "                 interpolation='nearest')\n",
    "    ax[i].axis('off')\n",
    "plt.savefig('gen_image.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "saver = tf.train.Saver(tdl.core.get_variables(model))\n",
    "saver.save(\n",
    "    session, \n",
    "    'tmp/{}_vars_{}{:02d}{:02d}:{:02d}{:02d}.ckpt'.format(\n",
    "        type(model).__name__,\n",
    "        now.year, now.month, now.day, now.hour, now.minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.embedding.components[0].loc.value().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, len(dis.real_pyramid), figsize=(20, 7))\n",
    "real_pyramid_ = session.run(dis.real_pyramid)\n",
    "sim_pyramid_ = session.run(dis.sim_pyramid)\n",
    "for idx in range(len(dis.real_pyramid)):\n",
    "    ax[0, idx].imshow(np.squeeze(normalize(real_pyramid_[idx][1, ...])),\n",
    "                      interpolation='nearest')\n",
    "    ax[1, idx].imshow(np.squeeze(normalize(sim_pyramid_[idx][-1, ...])),\n",
    "                      interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits = model.embedding.logits.value().eval()\n",
    "np.save('logits_tmp.pkl', _logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_h = tf.placeholder(dtype=tf.float32)\n",
    "logits_op = model.embedding.logits.assign(logits_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits = model.embedding.logits.value().eval()\n",
    "logits_op.eval({logits_h: np.array([30.0 if i == 71 else 0.0 \n",
    "                                    for i in range(100)])})\n",
    "\n",
    "# plot\n",
    "def normalize(image):\n",
    "    return ((image-image.min())/(image.max()-image.min()))\n",
    "fig, ax = plt.subplots(4,4, figsize=(15, 15))\n",
    "ax = np.reshape(ax, 4*4)\n",
    "xsim =  session.run(gen.xsim) #dis.sim_pyramid[-1].eval()\n",
    "for i in range(4*4):\n",
    "    image = (xsim[i][:,:,:]+1)*0.5\n",
    "    ax[i].imshow(np.squeeze(normalize(image)),\n",
    "                 interpolation='nearest')\n",
    "    ax[i].axis('off')\n",
    "plt.savefig('gen_image.pdf')\n",
    "\n",
    "# restore\n",
    "logits_op.eval({logits_h: _logits});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<acgan.model.msg_gan.AffineLayer at 0x7faad90a86d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import twodlearn as tdl\n",
    "import tensorflow.keras.layers as tf_layers\n",
    "from acgan.model.msg_gan import (MSG_GAN, MSG_DiscriminatorTrainer, MSG_GeneratorTrainer,\n",
    "                      AffineLayer, Conv2DLayer, LEAKY_RATE)\n",
    "\n",
    "units = [32, 64, 64, 64]\n",
    "kernels = [[3,3], [3,3], [3,3], [3,3]]\n",
    "strides = [[2,2], [2,2], [2,2], [2,2]]\n",
    "padding = 'same'\n",
    "dropout=None\n",
    "embedding_size = 64 \n",
    "\n",
    "n_layers = len(units)\n",
    "padding = (padding if isinstance(padding, (list, tuple))\n",
    "           else [padding]*n_layers)\n",
    "\n",
    "model = tdl.stacked.StackedModel()\n",
    "for i in range(len(units)):\n",
    "    model.add(Conv2DLayer(\n",
    "        filters=units[i], strides=strides[i],\n",
    "        kernel_size=kernels[i], padding=padding[i]))\n",
    "    model.add(tf_layers.LeakyReLU(LEAKY_RATE))\n",
    "    if dropout is not None:\n",
    "        model.add(tf_layers.Dropout(rate=dropout))\n",
    "\n",
    "model.add(tf_layers.Flatten())\n",
    "model.add(AffineLayer(units=embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<twodlearn.bayesnet.bayesnet.NormalModel at 0x7fabd67bab70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(tdl.bayesnet.NormalModel(\n",
    "            loc=lambda x: x,\n",
    "            batch_shape=embedding_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "y = model(tf.zeros([10, 32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(10,) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl.core.array.reduce_sum_rightmost(y.log_prob(tf.zeros([10, 64])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
